{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of Adverse Reactions from Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to identify adverse reactions from tweets. These tweets were collected with an R script using Twiiter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"twitter_data_All_Final.csv\" is the file that contains all information extracted from Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"twitter_data_All_Final.csv\",header=0,quoting=0)\n",
    "data = pd.DataFrame(rawdata.iloc[:,[3,4,5,12,13,27,42,43]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``data`` is the dataframe containing tweets with its all attributes.\n",
    "\n",
    "This is how `data` looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>searchTerm</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buysextoys71</td>\n",
       "      <td>Buy top levothyroxine online on our free compa...</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rachillionaire</td>\n",
       "      <td>@femmebostonian @Cherrell_Brown This has been ...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>femmebostonian Cherrell_Brown</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>renae_dePerio</td>\n",
       "      <td>For a decade I was on Levothyroxine 137 mcg. I...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>junglismastiff</td>\n",
       "      <td>@yourAAH Hi could you tell me which of your UK...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yourAAH</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notsydvicious</td>\n",
       "      <td>And my levothyroxine</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buysextoys71</td>\n",
       "      <td>Buy top levothyroxine online on our free compa...</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Juniper_publish</td>\n",
       "      <td>Telephone Survey to Assess Substitution of Ele...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buysextoys71</td>\n",
       "      <td>Buy top levothyroxine online on our free compa...</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine.fatalities occur,  Ny p...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine. Ny puberty. Growth hor...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  \\\n",
       "0     buysextoys71  Buy top levothyroxine online on our free compa...   \n",
       "1   rachillionaire  @femmebostonian @Cherrell_Brown This has been ...   \n",
       "2    renae_dePerio  For a decade I was on Levothyroxine 137 mcg. I...   \n",
       "3   junglismastiff  @yourAAH Hi could you tell me which of your UK...   \n",
       "4    notsydvicious                               And my levothyroxine   \n",
       "5     buysextoys71  Buy top levothyroxine online on our free compa...   \n",
       "6  Juniper_publish  Telephone Survey to Assess Substitution of Ele...   \n",
       "7     buysextoys71  Buy top levothyroxine online on our free compa...   \n",
       "8  Princeaurora200  Dear pfiser, Thyroxine.fatalities occur,  Ny p...   \n",
       "9  Princeaurora200  Dear pfiser, Thyroxine. Ny puberty. Growth hor...   \n",
       "\n",
       "                source  retweet_count hashtags           mentions_screen_name  \\\n",
       "0         twittbot.net              0      NaN                            NaN   \n",
       "1   Twitter for iPhone              0      NaN  femmebostonian Cherrell_Brown   \n",
       "2   Twitter for iPhone              0      NaN                            NaN   \n",
       "3  Twitter for Android              0      NaN                        yourAAH   \n",
       "4   Twitter for iPhone              0      NaN                            NaN   \n",
       "5         twittbot.net              0      NaN                            NaN   \n",
       "6   Twitter Web Client              0      NaN                            NaN   \n",
       "7         twittbot.net              0      NaN                            NaN   \n",
       "8      Mobile Web (M2)              0      NaN                            NaN   \n",
       "9      Mobile Web (M2)              0      NaN                            NaN   \n",
       "\n",
       "      searchTerm disease  \n",
       "0  Levothyroxine  Cancer  \n",
       "1  Levothyroxine  Cancer  \n",
       "2  Levothyroxine  Cancer  \n",
       "3  Levothyroxine  Cancer  \n",
       "4  Levothyroxine  Cancer  \n",
       "5  Levothyroxine  Cancer  \n",
       "6  Levothyroxine  Cancer  \n",
       "7  Levothyroxine  Cancer  \n",
       "8  Levothyroxine  Cancer  \n",
       "9  Levothyroxine  Cancer  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Information of what is inside the `data` Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3941 entries, 0 to 3940\n",
      "Data columns (total 8 columns):\n",
      "screen_name             3941 non-null object\n",
      "text                    3941 non-null object\n",
      "source                  3941 non-null object\n",
      "retweet_count           3941 non-null int64\n",
      "hashtags                647 non-null object\n",
      "mentions_screen_name    2764 non-null object\n",
      "searchTerm              3941 non-null object\n",
      "disease                 3941 non-null object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 246.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Removing `mentions`, `urls` and `hashtags` from all the tweets\n",
    "\n",
    "2) Removing `puncutations`\n",
    "\n",
    "3) Converting data to `lowercase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chirag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\") \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#removing mentions, URL and hashtag symbols from all the tweets followed by removing punctuations, lower-casing the data\n",
    "\n",
    "\n",
    "mention = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z-_\\.]+[A-Za-z0-9])|(?<=^|(?<=[^a-zA-Z0-9-_\\.])) @([A-Za-z-_\\.]+[A-Za-z0-9])|(?<=^|(?<=[^a-zA-Z0-9-_\\.])).@([A-Za-z-_\\.]+[A-Za-z0-9])'\n",
    "url = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "hashtag = '(?:^|\\s)[＃#]{1}(\\w+)'\n",
    "\n",
    "\n",
    "for i in range(len(data['text'])):\n",
    "    \n",
    "    x = data.loc[i,'text']\n",
    "    x = re.sub(mention,'',x)\n",
    "    x = re.sub(url,'',x)\n",
    "    x = re.sub('#','',x)\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    x = re.sub(\"[^a-zA-Z]\", \" \", x) \n",
    "    x = re.sub('[ \\t\\n]+', ' ',x)\n",
    "    x = x.lower().strip().rstrip(string.punctuation).lstrip(string.punctuation).strip()\n",
    "    \n",
    "    #text is split into words and converted into lowercase\n",
    "    words = x.lower().split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    stops = set(stopwords.words(\"english\"))  ##Although we have not removed stop words, we have stored stop words in \"stops\" in case it is required for further analysis\n",
    "    #remove retweet 'abbreviation' from tweets\n",
    "    words = [w for w in words if not w in ('rt','RT')]\n",
    "\n",
    "    \n",
    "    cleaned_word_list = \" \".join([w for w in words if len(w)>1])\n",
    "    #print('cleaned:  ',cleaned_word_list)\n",
    "##A column 'Preprocess text' was added to the dataset\n",
    "    data.loc[i,'Preprocesstext'] = cleaned_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>searchTerm</th>\n",
       "      <th>disease</th>\n",
       "      <th>Preprocesstext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buysextoys71</td>\n",
       "      <td>Buy top levothyroxine online on our free compa...</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>buy top levothyroxine online on our free compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rachillionaire</td>\n",
       "      <td>@femmebostonian @Cherrell_Brown This has been ...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>femmebostonian Cherrell_Brown</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>this has been super helpful switched from levo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>renae_dePerio</td>\n",
       "      <td>For a decade I was on Levothyroxine 137 mcg. I...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>for decade was on levothyroxine mcg was not se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>junglismastiff</td>\n",
       "      <td>@yourAAH Hi could you tell me which of your UK...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yourAAH</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>hi could you tell me which of your uk pharmaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notsydvicious</td>\n",
       "      <td>And my levothyroxine</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>and my levothyroxine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buysextoys71</td>\n",
       "      <td>Buy top levothyroxine online on our free compa...</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>buy top levothyroxine online on our free compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Juniper_publish</td>\n",
       "      <td>Telephone Survey to Assess Substitution of Ele...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>telephone survey to assess substitution of ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buysextoys71</td>\n",
       "      <td>Buy top levothyroxine online on our free compa...</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>buy top levothyroxine online on our free compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine.fatalities occur,  Ny p...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>dear pfiser thyroxine fatalities occur ny pube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine. Ny puberty. Growth hor...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>dear pfiser thyroxine ny puberty growth hormon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  \\\n",
       "0     buysextoys71  Buy top levothyroxine online on our free compa...   \n",
       "1   rachillionaire  @femmebostonian @Cherrell_Brown This has been ...   \n",
       "2    renae_dePerio  For a decade I was on Levothyroxine 137 mcg. I...   \n",
       "3   junglismastiff  @yourAAH Hi could you tell me which of your UK...   \n",
       "4    notsydvicious                               And my levothyroxine   \n",
       "5     buysextoys71  Buy top levothyroxine online on our free compa...   \n",
       "6  Juniper_publish  Telephone Survey to Assess Substitution of Ele...   \n",
       "7     buysextoys71  Buy top levothyroxine online on our free compa...   \n",
       "8  Princeaurora200  Dear pfiser, Thyroxine.fatalities occur,  Ny p...   \n",
       "9  Princeaurora200  Dear pfiser, Thyroxine. Ny puberty. Growth hor...   \n",
       "\n",
       "                source  retweet_count hashtags           mentions_screen_name  \\\n",
       "0         twittbot.net              0      NaN                            NaN   \n",
       "1   Twitter for iPhone              0      NaN  femmebostonian Cherrell_Brown   \n",
       "2   Twitter for iPhone              0      NaN                            NaN   \n",
       "3  Twitter for Android              0      NaN                        yourAAH   \n",
       "4   Twitter for iPhone              0      NaN                            NaN   \n",
       "5         twittbot.net              0      NaN                            NaN   \n",
       "6   Twitter Web Client              0      NaN                            NaN   \n",
       "7         twittbot.net              0      NaN                            NaN   \n",
       "8      Mobile Web (M2)              0      NaN                            NaN   \n",
       "9      Mobile Web (M2)              0      NaN                            NaN   \n",
       "\n",
       "      searchTerm disease                                     Preprocesstext  \n",
       "0  Levothyroxine  Cancer  buy top levothyroxine online on our free compa...  \n",
       "1  Levothyroxine  Cancer  this has been super helpful switched from levo...  \n",
       "2  Levothyroxine  Cancer  for decade was on levothyroxine mcg was not se...  \n",
       "3  Levothyroxine  Cancer  hi could you tell me which of your uk pharmaci...  \n",
       "4  Levothyroxine  Cancer                               and my levothyroxine  \n",
       "5  Levothyroxine  Cancer  buy top levothyroxine online on our free compa...  \n",
       "6  Levothyroxine  Cancer  telephone survey to assess substitution of ele...  \n",
       "7  Levothyroxine  Cancer  buy top levothyroxine online on our free compa...  \n",
       "8  Levothyroxine  Cancer  dear pfiser thyroxine fatalities occur ny pube...  \n",
       "9  Levothyroxine  Cancer  dear pfiser thyroxine ny puberty growth hormon...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 3941 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"We have a total of {} tweets\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Duplicate items to avoid Redundancy and then reseting the index of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates\n",
    "data.duplicated('Preprocesstext')\n",
    "dataUnique = data.drop_duplicates(['Preprocesstext'])\n",
    "dataUnique = dataUnique.reset_index(drop = True)\n",
    "dataUnique=pd.DataFrame(dataUnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>searchTerm</th>\n",
       "      <th>disease</th>\n",
       "      <th>Preprocesstext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rachillionaire</td>\n",
       "      <td>@femmebostonian @Cherrell_Brown This has been ...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>femmebostonian Cherrell_Brown</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>this has been super helpful switched from levo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>renae_dePerio</td>\n",
       "      <td>For a decade I was on Levothyroxine 137 mcg. I...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>for decade was on levothyroxine mcg was not se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>junglismastiff</td>\n",
       "      <td>@yourAAH Hi could you tell me which of your UK...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yourAAH</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>hi could you tell me which of your uk pharmaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notsydvicious</td>\n",
       "      <td>And my levothyroxine</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>and my levothyroxine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juniper_publish</td>\n",
       "      <td>Telephone Survey to Assess Substitution of Ele...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>telephone survey to assess substitution of ele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  \\\n",
       "0   rachillionaire  @femmebostonian @Cherrell_Brown This has been ...   \n",
       "1    renae_dePerio  For a decade I was on Levothyroxine 137 mcg. I...   \n",
       "2   junglismastiff  @yourAAH Hi could you tell me which of your UK...   \n",
       "3    notsydvicious                               And my levothyroxine   \n",
       "4  Juniper_publish  Telephone Survey to Assess Substitution of Ele...   \n",
       "\n",
       "                source  retweet_count hashtags           mentions_screen_name  \\\n",
       "0   Twitter for iPhone              0      NaN  femmebostonian Cherrell_Brown   \n",
       "1   Twitter for iPhone              0      NaN                            NaN   \n",
       "2  Twitter for Android              0      NaN                        yourAAH   \n",
       "3   Twitter for iPhone              0      NaN                            NaN   \n",
       "4   Twitter Web Client              0      NaN                            NaN   \n",
       "\n",
       "      searchTerm disease                                     Preprocesstext  \n",
       "0  Levothyroxine  Cancer  this has been super helpful switched from levo...  \n",
       "1  Levothyroxine  Cancer  for decade was on levothyroxine mcg was not se...  \n",
       "2  Levothyroxine  Cancer  hi could you tell me which of your uk pharmaci...  \n",
       "3  Levothyroxine  Cancer                               and my levothyroxine  \n",
       "4  Levothyroxine  Cancer  telephone survey to assess substitution of ele...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataUnique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important step is to remove the tweets done for marketing purposes as it may not represent correct information we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are left with 1457 tweets after removing potential market tweets\n"
     ]
    }
   ],
   "source": [
    "# removing potential market tweets\n",
    "market = ['buy','purchase','purchased','insurance','insured','sell','advertise','resell','retail','endorse','endorsed','discount','consumer','pharmacy']\n",
    "dataUnique = dataUnique[~dataUnique.Preprocesstext.str.contains('|'.join(market))]\n",
    "\n",
    "dataUnique = pd.DataFrame(dataUnique).reset_index(drop=True)\n",
    "dataUnique.to_csv('Preprocessed_without_markets.csv',sep=',')\n",
    "print(\"We are left with {} tweets after removing potential market tweets\".format(dataUnique.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using TextBlob(Easiest Way to do sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify the `polarity` and `subjectivity` of the normalized text of tweets and add it as a column in our dataframe\n",
    "\n",
    "`Polarity` : `Polarity` takes into account the positive and negative terms in a sentence\n",
    "\n",
    "`Subjectivity` : `Subjective` sentence expresses some personal feelings, views, or beliefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "dataUnique['polarity'] = dataUnique.apply(lambda x: TextBlob(x['Preprocesstext']).sentiment.polarity, axis=1)\n",
    "dataUnique['subjectivity'] = dataUnique.apply(lambda x: TextBlob(x['Preprocesstext']).sentiment.subjectivity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>searchTerm</th>\n",
       "      <th>disease</th>\n",
       "      <th>Preprocesstext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rachillionaire</td>\n",
       "      <td>@femmebostonian @Cherrell_Brown This has been ...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>femmebostonian Cherrell_Brown</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>this has been super helpful switched from levo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>renae_dePerio</td>\n",
       "      <td>For a decade I was on Levothyroxine 137 mcg. I...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>for decade was on levothyroxine mcg was not se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>junglismastiff</td>\n",
       "      <td>@yourAAH Hi could you tell me which of your UK...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yourAAH</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>hi could you tell me which of your uk pharmaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notsydvicious</td>\n",
       "      <td>And my levothyroxine</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>and my levothyroxine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juniper_publish</td>\n",
       "      <td>Telephone Survey to Assess Substitution of Ele...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>telephone survey to assess substitution of ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine.fatalities occur,  Ny p...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>dear pfiser thyroxine fatalities occur ny pube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine. Ny puberty. Growth hor...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>dear pfiser thyroxine ny puberty growth hormon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>microRNA_papers</td>\n",
       "      <td>Serum microRNA profiles in athyroid patients o...</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>serum microrna profiles in athyroid patients o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ImagineThatBaby</td>\n",
       "      <td>RT @handmade_dorset: And there I was home agai...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>1</td>\n",
       "      <td>thyroidcancer thyroid hashimotos livingwell gr...</td>\n",
       "      <td>handmade_dorset</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>and there was home again what an adventure thy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>medschat</td>\n",
       "      <td>Levothyroxine And Ringing In The Ears https://...</td>\n",
       "      <td>MedsChat.com</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>levothyroxine and ringing in the ears</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  \\\n",
       "0   rachillionaire  @femmebostonian @Cherrell_Brown This has been ...   \n",
       "1    renae_dePerio  For a decade I was on Levothyroxine 137 mcg. I...   \n",
       "2   junglismastiff  @yourAAH Hi could you tell me which of your UK...   \n",
       "3    notsydvicious                               And my levothyroxine   \n",
       "4  Juniper_publish  Telephone Survey to Assess Substitution of Ele...   \n",
       "5  Princeaurora200  Dear pfiser, Thyroxine.fatalities occur,  Ny p...   \n",
       "6  Princeaurora200  Dear pfiser, Thyroxine. Ny puberty. Growth hor...   \n",
       "7  microRNA_papers  Serum microRNA profiles in athyroid patients o...   \n",
       "8  ImagineThatBaby  RT @handmade_dorset: And there I was home agai...   \n",
       "9         medschat  Levothyroxine And Ringing In The Ears https://...   \n",
       "\n",
       "                source  retweet_count  \\\n",
       "0   Twitter for iPhone              0   \n",
       "1   Twitter for iPhone              0   \n",
       "2  Twitter for Android              0   \n",
       "3   Twitter for iPhone              0   \n",
       "4   Twitter Web Client              0   \n",
       "5      Mobile Web (M2)              0   \n",
       "6      Mobile Web (M2)              0   \n",
       "7              dlvr.it              0   \n",
       "8   Twitter Web Client              1   \n",
       "9         MedsChat.com              0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8  thyroidcancer thyroid hashimotos livingwell gr...   \n",
       "9                                                NaN   \n",
       "\n",
       "            mentions_screen_name     searchTerm disease  \\\n",
       "0  femmebostonian Cherrell_Brown  Levothyroxine  Cancer   \n",
       "1                            NaN  Levothyroxine  Cancer   \n",
       "2                        yourAAH  Levothyroxine  Cancer   \n",
       "3                            NaN  Levothyroxine  Cancer   \n",
       "4                            NaN  Levothyroxine  Cancer   \n",
       "5                            NaN  Levothyroxine  Cancer   \n",
       "6                            NaN  Levothyroxine  Cancer   \n",
       "7                            NaN  Levothyroxine  Cancer   \n",
       "8                handmade_dorset  Levothyroxine  Cancer   \n",
       "9                            NaN  Levothyroxine  Cancer   \n",
       "\n",
       "                                      Preprocesstext  \n",
       "0  this has been super helpful switched from levo...  \n",
       "1  for decade was on levothyroxine mcg was not se...  \n",
       "2  hi could you tell me which of your uk pharmaci...  \n",
       "3                               and my levothyroxine  \n",
       "4  telephone survey to assess substitution of ele...  \n",
       "5  dear pfiser thyroxine fatalities occur ny pube...  \n",
       "6  dear pfiser thyroxine ny puberty growth hormon...  \n",
       "7  serum microrna profiles in athyroid patients o...  \n",
       "8  and there was home again what an adventure thy...  \n",
       "9              levothyroxine and ringing in the ears  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataUnique.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here above I tried to use an inbuild function to calculate sentiment, which failed very badly.\n",
    "### I am using the Handlabelled sentiment file in next section. I have done this manually.\n",
    "### After so much manual labelling, lets build a model that does this on its own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files/ Dataframes:\n",
    "    1) `sentiment` : Handlablled Sentiment file.\n",
    "    2) `sentiment_test` : Another set of tweets which model will label as per its training\n",
    "\n",
    "a) Here, we used `LabelEncoder` over the `Sentiment` column which would assign the values that is `positive` and `negative` an integer value (say `0` or `1`). Now, convert it to type `string`.\n",
    "\n",
    "b) Then we extract a random sample out of it. `Line 23`\n",
    "\n",
    "c) Converting the `Sentiment` in `sentiment_test` to `categorical variable`, then `label encoding` it, converting it to `string`\n",
    "\n",
    "d) Vectorizing the tweets using `Term Frequency-Inverse Document Frequency` i.e. `TF-IDF`. For further understanding, visit: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "##Training model for sentiments\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "##Training dataset built on every iteration of testing\n",
    "sentiment= pd.read_csv(\"DatasetsWithSentiments.csv\", header=0, delimiter=\",\", quoting=0)\n",
    "sentiment = sentiment.reset_index(drop=True)\n",
    "##Testing data for Sentiment Classification\n",
    "sentiment_test= pd.read_csv(\"Sentiment_test50.csv\", header=0, delimiter=\",\", quoting=0,encoding='latin-1')\n",
    "\n",
    "\n",
    "\n",
    "sentiment['Sentiment'] = sentiment['Sentiment'].astype('category')\n",
    "sentiment['Sentiment'] = le.fit_transform(sentiment['Sentiment'])\n",
    "sentiment['Sentiment'] = str(sentiment['Sentiment'])\n",
    "# print(type(sentiment['Sentiment']))\n",
    "\n",
    "\n",
    "#sentiment_test = sentiment_test.sample(frac=1, random_state= 100)\n",
    "sentiment['Sentiment'] = sentiment.Sentiment.str.lower()\n",
    "sentiment['text'] = sentiment.text.str.lower()\n",
    "sentiment = sentiment.sample(frac=1, random_state= 100)\n",
    "\n",
    "sentiment_test['Sentiment'] = sentiment_test['Sentiment'].astype('category')\n",
    "sentiment_test['Sentiment'] = le.fit_transform(sentiment_test['Sentiment'])\n",
    "sentiment_test['Sentiment'] = str(sentiment_test['Sentiment'])\n",
    "sentiment_test['Sentiment'] = sentiment_test.Sentiment.str.lower()\n",
    "\n",
    "#print(sentiment['Sentiment'])\n",
    "\n",
    "X_train_text = sentiment['text']\n",
    "y_train = sentiment['Sentiment']\n",
    "\n",
    "\n",
    "X_valid_text = sentiment_test['text']\n",
    "y_valid = sentiment_test['Sentiment']\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(min_df = 1)\n",
    "\n",
    "X_train = vect.fit_transform(X_train_text.values.astype('U'))\n",
    "\n",
    "\n",
    "X_valid = vect.transform(X_valid_text.values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `NaiveBayes` for sentiment classification\n",
    "\n",
    "Wondering why use `NaiveBayes`. \n",
    "\n",
    "Since, now `sentiments` features are now in vector format. They can be represented as : \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://sebastianraschka.com/images/blog/2014/naive_bayes_1/linear_vs_nonlinear_problems.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://sebastianraschka.com/images/blog/2014/naive_bayes_1/linear_vs_nonlinear_problems.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Checkout: https://sebastianraschka.com/Articles/2014_naive_bayes_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring and Metric Evaluation\n",
    "\n",
    "Types of Metrics:\n",
    "\n",
    "    1) Accuracy : Accuracy is ratio of correctly predicted observation to the total observations.\n",
    "    \n",
    "    2) Confusion Matrix : confusion matrix is a table that is used to describe the performance of model on a set of test data for which the true values are known.\n",
    "    \n",
    "    3) Classification Report : Builds the text report showing the main classification metrics.\n",
    "    \n",
    "    4) Precision : precision expresses the proportion of the data points our model says was relevant actually were relevant\n",
    "    \n",
    "    5) Recall : recall is the number of correct results divided by the number of results that should have been returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chirag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics  import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "p_valid = clf.predict(X_valid)\n",
    "#print(accuracy_score(y_valid, p_valid))\n",
    "\n",
    "sentiment_test['Sentiment_NB'] =np.array(p_valid) \n",
    "sentiment_test.to_csv('sentiment_test50_addedNBScore.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sentiment` is the file containing Hand-labelled sentiments\n",
    "\n",
    "Here, we extract all the `negative` tweets and remove the tweets that someone would have posted which is still under research or study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are left with 139 tweets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Sentiment = pd.read_csv(\"DatasetsWithSentiments.csv\",header=0)\n",
    "\n",
    "#Negative tweets\n",
    "dataUniqueNeg = Sentiment[Sentiment.Sentiment=='negative']\n",
    "# print(dataUniqueNeg.shape)\n",
    "\n",
    "# removing the tweets with research or study\n",
    "study = ['research','study','survey','clinical trial']\n",
    "dataUniqueNeg = dataUniqueNeg[~dataUniqueNeg.Preprocesstext.str.contains('|'.join(study))]\n",
    "\n",
    "dataUniqueNeg = dataUniqueNeg.dropna(subset=['Preprocesstext']).reset_index(drop=True)\n",
    "print(\"We are left with {} tweets.\".format(dataUniqueNeg.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "`Stemming`: `Stemming` is the process for reducing inflected (or sometimes derived) words to their stem, base or root form—generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. When we stem a mushroom, we chop off its stem and keep the cap that most people think of as the edible portion. Similarly, when we stem a word, we chop off its inflections and keep what hopefully represents the main essence of the word. Technically, it depends on the type of mushroom, and we’re throwing away the mushroom stems while keeping the word stems. Nonetheless, I hope the metaphor is useful.\n",
    "\n",
    "`Lemmatization` : `Lemmatization` is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.Going back to our mushrooms, even an amateur chef knows that you shouldn’t just chop off the stems with a knife. Instead, you should carefully remove the stems, cutting around them with a paring knife or gently twisting them off.`Lemmatization` tries to take a similarly careful approach to removing inflections. Lemmatization does not simply chop off inflections, but instead relies on a lexical knowledge base like WordNet to obtain the correct base forms of words.\n",
    "\n",
    "Great thanks to Mr.Daniel Tunkelang for this article: https://queryunderstanding.com/stemming-and-lemmatization-6c086742fe45\n",
    "\n",
    "There are several `stemming` techniques available out of which we are using `PorterStemmer` because : \n",
    "\n",
    "a) Most Gentle towards data.\n",
    "\n",
    "b) Significant Margin.\n",
    "\n",
    "More Info at: https://stackoverflow.com/questions/10554052/what-are-the-major-differences-and-benefits-of-porter-and-lancaster-stemming-alg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`General_ADR` is a csv file that contains list of `Adverse Reactions`. Steps followed:\n",
    "\n",
    "1) LowerCasing\n",
    "\n",
    "2) Lemmatizing the words, appending them to a list\n",
    "\n",
    "3) Creating its Dataframe and a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chirag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chirag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chirag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# reading the file with common adverse effects\n",
    "\n",
    "ADR = pd.read_csv(\"General_ADR.csv\")\n",
    "ADR['Adr'] = ADR.adr.str.lower()\n",
    "ADR_stem = []\n",
    "for adr in ADR['adr']:\n",
    "    adr = lemmatizer.lemmatize(adr)\n",
    "    ADR_stem.append(adr)\n",
    "    \n",
    "ADR_stem = pd.DataFrame(ADR_stem)\n",
    "ADRset = ADR_stem.apply(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several Functions are created in this block. They work as follows:\n",
    "\n",
    "1) featureExtraction: Looping is done over each word in the review and if it is in the model's vocabulary then its feature vector is added to the total.\n",
    "\n",
    "2) search: This function searched for text and retrieves 'n' words eother side of the text, which are returned seperately.\n",
    "\n",
    "3) phraseBuilder: It helps in buildin the phrases for Adverse reactions and uses the `search` function declared above.\n",
    "\n",
    "4) Drug_text_wostem : It is used to treat text with lemmatizer and stemmer to extract Adverse Reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(vocab):\n",
    "    nwords = []\n",
    "\n",
    "    for word in vocab:\n",
    "        \n",
    "        if any(word in s for s in ADRset):\n",
    "            nwords.append(word)\n",
    "            #featureVec = np.add(featureVec,model[word])\n",
    "                \n",
    "    return nwords\n",
    "\n",
    "\n",
    "def search(text,search_word,n):\n",
    "    \n",
    "    word = r\"\\W*([\\w]+)\"\n",
    "    phrase = re.search(r'{}\\W*{}{}'.format(word*n,search_word, word*n), text)\n",
    "    if phrase is not None:\n",
    "        groups = phrase.groups()\n",
    "        phrase1 = \" \".join(groups[:n])\n",
    "        phrase2 = search_word\n",
    "        phrase3 = \" \".join(groups[n:])\n",
    "        finalphrase1 = phrase1 + ' '+ phrase2\n",
    "        finalphrase2 = phrase2+' ' +phrase3\n",
    "        return finalphrase1, finalphrase2\n",
    "\n",
    "def phraseBuilder(text_drug):\n",
    "    \n",
    "    Symptoms = []\n",
    "    if not text_drug.empty:\n",
    "        for i in range(len(text_drug)):\n",
    "            ADR = text_drug['ADRE'][i]\n",
    "            text = text_drug['Preprocesstext'][i]\n",
    "            finalphrase = []\n",
    "            if len(ADR) and len(text)>0:\n",
    "                for adr in ADR:\n",
    "                    phrase1 = search(text,adr,2)\n",
    "                    finalphrase.append(phrase1)\n",
    "            Symptoms.append(finalphrase)\n",
    "        Symptoms = np.array(Symptoms)\n",
    "\n",
    "        text_drug['Symptoms'] = Symptoms\n",
    "        return text_drug\n",
    "##treating text with lemmatizer and extracting ADR\n",
    "def Drug_text_wostem(text_drug):\n",
    "    if not text_drug.empty:\n",
    "        TwitterText_Drug = []\n",
    "        for i in range(len(text_drug['Preprocesstext'])):\n",
    "            tweet = text_drug.loc[i,'Preprocesstext']\n",
    "\n",
    "            token =nltk.word_tokenize(tweet)\n",
    "           \n",
    "            #Stem the words.\n",
    "            text = [lemmatizer.lemmatize(t) for t in token]\n",
    "\n",
    "            TwitterText_Drug.append(text)\n",
    "        TwitterText_Drug = np.array(TwitterText_Drug)   \n",
    "        text_drug['words'] = TwitterText_Drug\n",
    "\n",
    "        ####calling the featureExtraction function to extraxt ADR from each review###\n",
    "        ADRE = []\n",
    "        ADRTweet=[]\n",
    "        for i in range(len(text_drug['words'])):\n",
    "            ADR = featureExtraction(text_drug['words'][i])\n",
    "            ADRE.append(ADR)\n",
    "\n",
    "        #ADRE \n",
    "        text_drug['ADRE'] = ADRE\n",
    "        text_drug = phraseBuilder(text_drug)\n",
    "        text_drug = pd.DataFrame(text_drug)\n",
    "        text_drug = text_drug[text_drug['ADRE'].map(lambda d: len(d)) > 0]\n",
    "        return text_drug\n",
    "\n",
    "\n",
    "def Drug_text(text_drug):\n",
    "    if not text_drug.empty:\n",
    "        TwitterText_Drug = []\n",
    "        for i in range(len(text_drug['Preprocesstext'])):\n",
    "            tweet = text_drug.loc[i,'Preprocesstext']\n",
    "\n",
    "            token =nltk.word_tokenize(tweet)\n",
    "            \n",
    "            #lemmatize and Stem the words.\n",
    "            text = [lemmatizer.lemmatize(t) for t in token]\n",
    "            text = [ps.stem(t) for t in text]\n",
    "            \n",
    "            TwitterText_Drug.append(text)\n",
    "        TwitterText_Drug = np.array(TwitterText_Drug)   \n",
    "        #TwitterText_Drug\n",
    "        text_drug['words'] = TwitterText_Drug\n",
    "\n",
    "        ####calling the featureExtraction function to extraxt ADR from each review###\n",
    "        ADRE = []\n",
    "        ADRTweet=[]\n",
    "        for i in range(len(text_drug['words'])):\n",
    "            ADR = featureExtraction(text_drug['words'][i])\n",
    "\n",
    "            ADRE.append(ADR)\n",
    "\n",
    "        #ADRE \n",
    "        text_drug['ADRE'] = ADRE\n",
    "        text_drug = phraseBuilder(text_drug)\n",
    "        text_drug = pd.DataFrame(text_drug)\n",
    "        ##keeping the rows with the tweets with ADRE\n",
    "        text_drug = text_drug[text_drug['ADRE'].map(lambda d: len(d)) > 0]\n",
    "        return text_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatized Text Only: \n",
    "\n",
    "Fetching the dataset with Adverse Reaction for text treated with Lemmatizer and saving it in a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = Drug_text_wostem(dataUniqueNeg)\n",
    "a1.to_csv('Tweets with ADR_with Lem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized and Stemmed Data :\n",
    "\n",
    "Fetching the dataset with Adverse Reaction for text treated with lemmatizer and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = Drug_text(dataUniqueNeg)\n",
    "a2.to_csv('Tweets with ADR_with Lem and Stem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FDA_Drug_Effects.csv` contains some of the Adverse Side Effects. \n",
    "\n",
    "We stem and lemmatize each word for comparision with the words extracted in previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = pd.read_csv('FDA_Drug_effects.csv')\n",
    "specific_stem = []\n",
    "for i in range(len(specific)):\n",
    "    words = specific.SideEffects[i]\n",
    "    text = []\n",
    "    text = words.lower().split()\n",
    "    text = [lemmatizer.lemmatize(t) for t in text]\n",
    "    text = [ps.stem(t) for t in text]\n",
    "    specific_stem.append(text)\n",
    "    \n",
    "specific_stem = np.array(specific_stem)\n",
    "specific_stem\n",
    "specific['SideEffectToken'] = specific_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a new dataset which is join between the specific dataset and dataset with adverse reactions from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(a2, specific, on='searchTerm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>searchTerm</th>\n",
       "      <th>disease</th>\n",
       "      <th>Preprocesstext</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ADRE</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>SideEffects</th>\n",
       "      <th>Unspecified_ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>renae_dePerio</td>\n",
       "      <td>For a decade I was on Levothyroxine 137 mcg. I...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>for decade was on levothyroxine mcg was not se...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[up, bad, heart]</td>\n",
       "      <td>[(even bumped up, up to mcg), (it caused bad, ...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[up, bad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Princeaurora200</td>\n",
       "      <td>Dear pfiser, Thyroxine.fatalities occur,  Ny p...</td>\n",
       "      <td>Mobile Web (M2)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>dear pfiser thyroxine fatalities occur ny pube...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[fatal]</td>\n",
       "      <td>[(pfiser thyroxine fatal, fatal ities occur)]</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[fatal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scottisaacsmd</td>\n",
       "      <td>Treating  borderline low thyroid levels can in...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>treating borderline low thyroid levels can inc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[low, thyroid, can, risk, death]</td>\n",
       "      <td>[(treating borderline low, low thyroid levels)...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[low, thyroid, can, risk, death]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MINXY_ROCHELLE</td>\n",
       "      <td>@TaylorHelga Ive always been prescribed levoth...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TaylorHelga</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>ive always been prescribed levothyroxine for u...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[thyroid, weight]</td>\n",
       "      <td>[(for underactive thyroid, thyroid still strug...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[thyroid, weight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scchapterofacp</td>\n",
       "      <td>Levothyroxine therapy may increase risk for de...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>levothyroxine therapy may increase risk for de...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[may, risk, death]</td>\n",
       "      <td>[(levothyroxine therapy may, may increase risk...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[may, risk, death]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sarahoelker</td>\n",
       "      <td>The implicit \"OMG you're addicted\" message her...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>the implicit omg you re addicted message here ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[addict, addict, up]</td>\n",
       "      <td>[(you re addict, addict ed message), (you re a...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[addict, addict, up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bringinsexybach</td>\n",
       "      <td>@C_GraceT I also couldn't stop taking my levot...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C_GraceT</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>also couldn stop taking my levothyroxine witho...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[thyroid]</td>\n",
       "      <td>[(on synthetic thyroid, thyroid hormone huh)]</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[thyroid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>priellan</td>\n",
       "      <td>would you get call someone with hypothyroidism...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>would you get call someone with hypothyroidism...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[thyroid]</td>\n",
       "      <td>[(with hypo thyroid, thyroid ism dependent)]</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[thyroid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KijonaiaArt</td>\n",
       "      <td>@kittykaya Nonono, he's sometimes up UNTIL 2-3...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kittykaya</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>nonono he sometimes up until am actually just ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[up, insomnia, back, blood]</td>\n",
       "      <td>[(he sometimes up, up until am), (might be ins...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[up, insomnia, back, blood]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KijonaiaArt</td>\n",
       "      <td>@bunnieandbea See, Scott sleeps in so late no ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bunnieandbea</td>\n",
       "      <td>Levothyroxine</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>see scott sleeps in so late no matter when he ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sleep, up]</td>\n",
       "      <td>[(see scott sleep, sleep s in), (to wake up, u...</td>\n",
       "      <td>tummy trouble,boner kryptonite,chest infection...</td>\n",
       "      <td>[up]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  \\\n",
       "0    renae_dePerio  For a decade I was on Levothyroxine 137 mcg. I...   \n",
       "1  Princeaurora200  Dear pfiser, Thyroxine.fatalities occur,  Ny p...   \n",
       "2    scottisaacsmd  Treating  borderline low thyroid levels can in...   \n",
       "3   MINXY_ROCHELLE  @TaylorHelga Ive always been prescribed levoth...   \n",
       "4   scchapterofacp  Levothyroxine therapy may increase risk for de...   \n",
       "5      sarahoelker  The implicit \"OMG you're addicted\" message her...   \n",
       "6  bringinsexybach  @C_GraceT I also couldn't stop taking my levot...   \n",
       "7         priellan  would you get call someone with hypothyroidism...   \n",
       "8      KijonaiaArt  @kittykaya Nonono, he's sometimes up UNTIL 2-3...   \n",
       "9      KijonaiaArt  @bunnieandbea See, Scott sleeps in so late no ...   \n",
       "\n",
       "                source  retweet_count hashtags mentions_screen_name  \\\n",
       "0   Twitter for iPhone              0      NaN                  NaN   \n",
       "1      Mobile Web (M2)              0      NaN                  NaN   \n",
       "2             LinkedIn              0      NaN                  NaN   \n",
       "3  Twitter for Android              0      NaN          TaylorHelga   \n",
       "4   Twitter Web Client              0      NaN                  NaN   \n",
       "5            TweetDeck              0      NaN                  NaN   \n",
       "6   Twitter Web Client              0      NaN             C_GraceT   \n",
       "7            TweetDeck              0      NaN                  NaN   \n",
       "8   Twitter Web Client              0      NaN            kittykaya   \n",
       "9   Twitter Web Client              0      NaN         bunnieandbea   \n",
       "\n",
       "      searchTerm disease                                     Preprocesstext  \\\n",
       "0  Levothyroxine  Cancer  for decade was on levothyroxine mcg was not se...   \n",
       "1  Levothyroxine  Cancer  dear pfiser thyroxine fatalities occur ny pube...   \n",
       "2  Levothyroxine  Cancer  treating borderline low thyroid levels can inc...   \n",
       "3  Levothyroxine  Cancer  ive always been prescribed levothyroxine for u...   \n",
       "4  Levothyroxine  Cancer  levothyroxine therapy may increase risk for de...   \n",
       "5  Levothyroxine  Cancer  the implicit omg you re addicted message here ...   \n",
       "6  Levothyroxine  Cancer  also couldn stop taking my levothyroxine witho...   \n",
       "7  Levothyroxine  Cancer  would you get call someone with hypothyroidism...   \n",
       "8  Levothyroxine  Cancer  nonono he sometimes up until am actually just ...   \n",
       "9  Levothyroxine  Cancer  see scott sleeps in so late no matter when he ...   \n",
       "\n",
       "  Sentiment                              ADRE  \\\n",
       "0  negative                  [up, bad, heart]   \n",
       "1  negative                           [fatal]   \n",
       "2  negative  [low, thyroid, can, risk, death]   \n",
       "3  negative                 [thyroid, weight]   \n",
       "4  negative                [may, risk, death]   \n",
       "5  negative              [addict, addict, up]   \n",
       "6  negative                         [thyroid]   \n",
       "7  negative                         [thyroid]   \n",
       "8  negative       [up, insomnia, back, blood]   \n",
       "9  negative                       [sleep, up]   \n",
       "\n",
       "                                            Symptoms  \\\n",
       "0  [(even bumped up, up to mcg), (it caused bad, ...   \n",
       "1      [(pfiser thyroxine fatal, fatal ities occur)]   \n",
       "2  [(treating borderline low, low thyroid levels)...   \n",
       "3  [(for underactive thyroid, thyroid still strug...   \n",
       "4  [(levothyroxine therapy may, may increase risk...   \n",
       "5  [(you re addict, addict ed message), (you re a...   \n",
       "6      [(on synthetic thyroid, thyroid hormone huh)]   \n",
       "7       [(with hypo thyroid, thyroid ism dependent)]   \n",
       "8  [(he sometimes up, up until am), (might be ins...   \n",
       "9  [(see scott sleep, sleep s in), (to wake up, u...   \n",
       "\n",
       "                                         SideEffects  \\\n",
       "0  tummy trouble,boner kryptonite,chest infection...   \n",
       "1  tummy trouble,boner kryptonite,chest infection...   \n",
       "2  tummy trouble,boner kryptonite,chest infection...   \n",
       "3  tummy trouble,boner kryptonite,chest infection...   \n",
       "4  tummy trouble,boner kryptonite,chest infection...   \n",
       "5  tummy trouble,boner kryptonite,chest infection...   \n",
       "6  tummy trouble,boner kryptonite,chest infection...   \n",
       "7  tummy trouble,boner kryptonite,chest infection...   \n",
       "8  tummy trouble,boner kryptonite,chest infection...   \n",
       "9  tummy trouble,boner kryptonite,chest infection...   \n",
       "\n",
       "                    Unspecified_ADR  \n",
       "0                         [up, bad]  \n",
       "1                           [fatal]  \n",
       "2  [low, thyroid, can, risk, death]  \n",
       "3                 [thyroid, weight]  \n",
       "4                [may, risk, death]  \n",
       "5              [addict, addict, up]  \n",
       "6                         [thyroid]  \n",
       "7                         [thyroid]  \n",
       "8       [up, insomnia, back, blood]  \n",
       "9                              [up]  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code compares the words extracted per tweet to the bag of words of the corresponding `searchTerm` i.e. drug. \n",
    "\n",
    "The words that do not match are appended in a column called `Unspecified_ADR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unidentified_ADR = []\n",
    "for i in range(len(result)):\n",
    " \n",
    "    adr = result['ADRE'][i]\n",
    "    UnADR = []\n",
    "    for word in adr:\n",
    "        if not any(word in s for s in result['SideEffectToken'][i]):\n",
    "\n",
    "            UnADR.append(word)\n",
    "    Unidentified_ADR.append(UnADR)\n",
    "Unidentified_ADR = np.array(Unidentified_ADR)\n",
    "Unidentified_ADR\n",
    "result['Unspecified_ADR'] = Unidentified_ADR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a csv for the final result after dropping the `SideEffectToken` and words since they are redundant to the other columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV with ADRs done.\n"
     ]
    }
   ],
   "source": [
    "result = result.drop(['SideEffectToken','words'],axis = 1).reset_index(drop=True)\n",
    "#result.to_csv('TweetsWithUnidentifiedSideEffects.csv', sep=',')\n",
    "result.to_csv('TweetsWithUnidentifiedSideEffectsStem.csv', sep=',')\n",
    "print('CSV with ADRs done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
